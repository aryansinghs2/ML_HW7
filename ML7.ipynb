{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cff92126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "1563/1563 [==============================] - 29s 18ms/step - loss: 1.4784 - accuracy: 0.4633 - val_loss: 1.2066 - val_accuracy: 0.5682\n",
      "Epoch 2/300\n",
      "1563/1563 [==============================] - 29s 19ms/step - loss: 1.0785 - accuracy: 0.6178 - val_loss: 1.0414 - val_accuracy: 0.6367\n",
      "Epoch 3/300\n",
      "1563/1563 [==============================] - 29s 18ms/step - loss: 0.9144 - accuracy: 0.6794 - val_loss: 0.9622 - val_accuracy: 0.6585\n",
      "Epoch 4/300\n",
      "1563/1563 [==============================] - 28s 18ms/step - loss: 0.8149 - accuracy: 0.7156 - val_loss: 0.8780 - val_accuracy: 0.6931\n",
      "Epoch 5/300\n",
      "1563/1563 [==============================] - 28s 18ms/step - loss: 0.7286 - accuracy: 0.7432 - val_loss: 0.8428 - val_accuracy: 0.7098\n",
      "Epoch 6/300\n",
      "1563/1563 [==============================] - 28s 18ms/step - loss: 0.6588 - accuracy: 0.7695 - val_loss: 0.8313 - val_accuracy: 0.7125\n",
      "Epoch 7/300\n",
      "1563/1563 [==============================] - 28s 18ms/step - loss: 0.6021 - accuracy: 0.7899 - val_loss: 0.8223 - val_accuracy: 0.7284\n",
      "Epoch 8/300\n",
      "1563/1563 [==============================] - 28s 18ms/step - loss: 0.5460 - accuracy: 0.8078 - val_loss: 0.8808 - val_accuracy: 0.7210\n",
      "Epoch 9/300\n",
      "1563/1563 [==============================] - 28s 18ms/step - loss: 0.4971 - accuracy: 0.8246 - val_loss: 0.8526 - val_accuracy: 0.7222\n",
      "Epoch 10/300\n",
      "1563/1563 [==============================] - 32s 20ms/step - loss: 0.4408 - accuracy: 0.8436 - val_loss: 0.8997 - val_accuracy: 0.7151\n",
      "Epoch 11/300\n",
      "1563/1563 [==============================] - 32s 20ms/step - loss: 0.3968 - accuracy: 0.8595 - val_loss: 0.9569 - val_accuracy: 0.7099\n",
      "Epoch 12/300\n",
      "1563/1563 [==============================] - 32s 21ms/step - loss: 0.3523 - accuracy: 0.8749 - val_loss: 1.0287 - val_accuracy: 0.7135\n",
      "Epoch 13/300\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.3178 - accuracy: 0.8856 - val_loss: 1.0921 - val_accuracy: 0.7046\n",
      "Epoch 14/300\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.2844 - accuracy: 0.8969 - val_loss: 1.1803 - val_accuracy: 0.7092\n",
      "Epoch 15/300\n",
      "1563/1563 [==============================] - 31s 20ms/step - loss: 0.2479 - accuracy: 0.9118 - val_loss: 1.2244 - val_accuracy: 0.7004\n",
      "Epoch 16/300\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.2286 - accuracy: 0.9180 - val_loss: 1.2818 - val_accuracy: 0.7148\n",
      "Epoch 17/300\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.2070 - accuracy: 0.9256 - val_loss: 1.3910 - val_accuracy: 0.7058\n",
      "Epoch 18/300\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.1894 - accuracy: 0.9315 - val_loss: 1.5526 - val_accuracy: 0.6983\n",
      "Epoch 19/300\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.1769 - accuracy: 0.9365 - val_loss: 1.5773 - val_accuracy: 0.6981\n",
      "Epoch 20/300\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.1626 - accuracy: 0.9422 - val_loss: 1.6484 - val_accuracy: 0.6934\n",
      "Epoch 21/300\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.1598 - accuracy: 0.9422 - val_loss: 1.7256 - val_accuracy: 0.6874\n",
      "Epoch 22/300\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.1491 - accuracy: 0.9484 - val_loss: 1.7895 - val_accuracy: 0.6890\n",
      "Epoch 23/300\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.1333 - accuracy: 0.9531 - val_loss: 1.8916 - val_accuracy: 0.6834\n",
      "Epoch 24/300\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.1432 - accuracy: 0.9502 - val_loss: 1.9580 - val_accuracy: 0.6879\n",
      "Epoch 25/300\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.1280 - accuracy: 0.9551 - val_loss: 1.9366 - val_accuracy: 0.6992\n",
      "Epoch 26/300\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.1228 - accuracy: 0.9567 - val_loss: 2.0882 - val_accuracy: 0.6886\n",
      "Epoch 27/300\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.1181 - accuracy: 0.9588 - val_loss: 2.1394 - val_accuracy: 0.6945\n",
      "Epoch 28/300\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.1180 - accuracy: 0.9586 - val_loss: 2.1604 - val_accuracy: 0.6924\n",
      "Epoch 29/300\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.1218 - accuracy: 0.9588 - val_loss: 2.1594 - val_accuracy: 0.6956\n",
      "Epoch 30/300\n",
      "1563/1563 [==============================] - 31s 20ms/step - loss: 0.1179 - accuracy: 0.9592 - val_loss: 2.1130 - val_accuracy: 0.6912\n",
      "Epoch 31/300\n",
      "1563/1563 [==============================] - 31s 20ms/step - loss: 0.1030 - accuracy: 0.9646 - val_loss: 2.2798 - val_accuracy: 0.6922\n",
      "Epoch 32/300\n",
      "1563/1563 [==============================] - 31s 20ms/step - loss: 0.1165 - accuracy: 0.9610 - val_loss: 2.4152 - val_accuracy: 0.6816\n",
      "Epoch 33/300\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.1034 - accuracy: 0.9643 - val_loss: 2.3790 - val_accuracy: 0.6966\n",
      "Epoch 34/300\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.1076 - accuracy: 0.9644 - val_loss: 2.4300 - val_accuracy: 0.6916\n",
      "Epoch 35/300\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.1016 - accuracy: 0.9664 - val_loss: 2.4914 - val_accuracy: 0.6953\n",
      "Epoch 36/300\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.1016 - accuracy: 0.9661 - val_loss: 2.4623 - val_accuracy: 0.6958\n",
      "Epoch 37/300\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.1053 - accuracy: 0.9654 - val_loss: 2.4821 - val_accuracy: 0.6993\n",
      "Epoch 38/300\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.0965 - accuracy: 0.9681 - val_loss: 2.5721 - val_accuracy: 0.6938\n",
      "Epoch 39/300\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.0943 - accuracy: 0.9701 - val_loss: 2.7641 - val_accuracy: 0.6755\n",
      "Epoch 40/300\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.1015 - accuracy: 0.9664 - val_loss: 2.7218 - val_accuracy: 0.6895\n",
      "Epoch 41/300\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.0920 - accuracy: 0.9701 - val_loss: 2.6446 - val_accuracy: 0.7056\n",
      "Epoch 42/300\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.0900 - accuracy: 0.9714 - val_loss: 2.6829 - val_accuracy: 0.6939\n",
      "Epoch 43/300\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.0950 - accuracy: 0.9698 - val_loss: 2.8150 - val_accuracy: 0.6928\n",
      "Epoch 44/300\n",
      "1563/1563 [==============================] - 31s 20ms/step - loss: 0.0949 - accuracy: 0.9694 - val_loss: 2.7062 - val_accuracy: 0.6903\n",
      "Epoch 45/300\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.0946 - accuracy: 0.9703 - val_loss: 2.9160 - val_accuracy: 0.6896\n",
      "Epoch 46/300\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.0847 - accuracy: 0.9725 - val_loss: 2.8955 - val_accuracy: 0.6927\n",
      "Epoch 47/300\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.0933 - accuracy: 0.9704 - val_loss: 2.8325 - val_accuracy: 0.6912\n",
      "Epoch 48/300\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.0867 - accuracy: 0.9728 - val_loss: 2.9015 - val_accuracy: 0.6900\n",
      "Epoch 49/300\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.0841 - accuracy: 0.9725 - val_loss: 2.9518 - val_accuracy: 0.6893\n",
      "Epoch 50/300\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.0851 - accuracy: 0.9732 - val_loss: 3.1219 - val_accuracy: 0.6898\n",
      "Epoch 51/300\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.0894 - accuracy: 0.9720 - val_loss: 3.2100 - val_accuracy: 0.6767\n",
      "Epoch 52/300\n",
      "1563/1563 [==============================] - 31s 20ms/step - loss: 0.0883 - accuracy: 0.9726 - val_loss: 3.0537 - val_accuracy: 0.6975\n",
      "Epoch 53/300\n",
      "1563/1563 [==============================] - 31s 20ms/step - loss: 0.0838 - accuracy: 0.9738 - val_loss: 3.1641 - val_accuracy: 0.6923\n",
      "Epoch 54/300\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.0769 - accuracy: 0.9761 - val_loss: 3.0717 - val_accuracy: 0.6882\n",
      "Epoch 55/300\n",
      "1563/1563 [==============================] - 31s 20ms/step - loss: 0.0887 - accuracy: 0.9727 - val_loss: 3.0825 - val_accuracy: 0.6936\n",
      "Epoch 56/300\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.0770 - accuracy: 0.9757 - val_loss: 3.2355 - val_accuracy: 0.6949\n",
      "Epoch 57/300\n",
      "1563/1563 [==============================] - 29s 18ms/step - loss: 0.0826 - accuracy: 0.9747 - val_loss: 3.1333 - val_accuracy: 0.6918\n",
      "Epoch 58/300\n",
      "1563/1563 [==============================] - 28s 18ms/step - loss: 0.0819 - accuracy: 0.9744 - val_loss: 3.2365 - val_accuracy: 0.6866\n",
      "Epoch 59/300\n",
      "1563/1563 [==============================] - 28s 18ms/step - loss: 0.0782 - accuracy: 0.9756 - val_loss: 3.2624 - val_accuracy: 0.6856\n",
      "Epoch 60/300\n",
      "1563/1563 [==============================] - 28s 18ms/step - loss: 0.0798 - accuracy: 0.9758 - val_loss: 3.4029 - val_accuracy: 0.6878\n",
      "Epoch 61/300\n",
      "1563/1563 [==============================] - 28s 18ms/step - loss: 0.0795 - accuracy: 0.9762 - val_loss: 3.2314 - val_accuracy: 0.6838\n",
      "Epoch 62/300\n",
      "1563/1563 [==============================] - 28s 18ms/step - loss: 0.0735 - accuracy: 0.9775 - val_loss: 3.3347 - val_accuracy: 0.6955\n",
      "Epoch 63/300\n",
      "1563/1563 [==============================] - 28s 18ms/step - loss: 0.0899 - accuracy: 0.9731 - val_loss: 3.3041 - val_accuracy: 0.6869\n",
      "Epoch 64/300\n",
      "1563/1563 [==============================] - 28s 18ms/step - loss: 0.0736 - accuracy: 0.9784 - val_loss: 3.3106 - val_accuracy: 0.6881\n",
      "Epoch 65/300\n",
      "1563/1563 [==============================] - 29s 19ms/step - loss: 0.0785 - accuracy: 0.9764 - val_loss: 3.5207 - val_accuracy: 0.6867\n",
      "Epoch 66/300\n",
      "1563/1563 [==============================] - 28s 18ms/step - loss: 0.0813 - accuracy: 0.9751 - val_loss: 3.3672 - val_accuracy: 0.6929\n",
      "Epoch 67/300\n",
      "1563/1563 [==============================] - 28s 18ms/step - loss: 0.0737 - accuracy: 0.9785 - val_loss: 3.3928 - val_accuracy: 0.6825\n",
      "Epoch 68/300\n",
      "1563/1563 [==============================] - 28s 18ms/step - loss: 0.0741 - accuracy: 0.9776 - val_loss: 3.5376 - val_accuracy: 0.6926\n",
      "Epoch 69/300\n",
      "1563/1563 [==============================] - 28s 18ms/step - loss: 0.0682 - accuracy: 0.9789 - val_loss: 3.4525 - val_accuracy: 0.6881\n",
      "Epoch 70/300\n",
      "1563/1563 [==============================] - 28s 18ms/step - loss: 0.0772 - accuracy: 0.9764 - val_loss: 3.5162 - val_accuracy: 0.6960\n",
      "Epoch 71/300\n",
      "1563/1563 [==============================] - 28s 18ms/step - loss: 0.0739 - accuracy: 0.9774 - val_loss: 3.6372 - val_accuracy: 0.6857\n",
      "Epoch 72/300\n",
      "1563/1563 [==============================] - 28s 18ms/step - loss: 0.0756 - accuracy: 0.9779 - val_loss: 3.6522 - val_accuracy: 0.6916\n",
      "Epoch 73/300\n",
      "1563/1563 [==============================] - 28s 18ms/step - loss: 0.0736 - accuracy: 0.9785 - val_loss: 3.5558 - val_accuracy: 0.6904\n",
      "Epoch 74/300\n",
      "1563/1563 [==============================] - 29s 18ms/step - loss: 0.0706 - accuracy: 0.9787 - val_loss: 3.5990 - val_accuracy: 0.6906\n",
      "Epoch 75/300\n",
      "1563/1563 [==============================] - 29s 18ms/step - loss: 0.0855 - accuracy: 0.9768 - val_loss: 3.6881 - val_accuracy: 0.6913\n",
      "Epoch 76/300\n",
      "1563/1563 [==============================] - 29s 19ms/step - loss: 0.0593 - accuracy: 0.9826 - val_loss: 3.6368 - val_accuracy: 0.6931\n",
      "Epoch 77/300\n",
      "1563/1563 [==============================] - 28s 18ms/step - loss: 0.0826 - accuracy: 0.9761 - val_loss: 3.8088 - val_accuracy: 0.6864\n",
      "Epoch 78/300\n",
      "1563/1563 [==============================] - 28s 18ms/step - loss: 0.0679 - accuracy: 0.9808 - val_loss: 3.9968 - val_accuracy: 0.6866\n",
      "Epoch 79/300\n",
      "1563/1563 [==============================] - 28s 18ms/step - loss: 0.0718 - accuracy: 0.9797 - val_loss: 3.9281 - val_accuracy: 0.6914\n",
      "Epoch 80/300\n",
      "1563/1563 [==============================] - 29s 19ms/step - loss: 0.0794 - accuracy: 0.9795 - val_loss: 3.8134 - val_accuracy: 0.6865\n",
      "Epoch 81/300\n",
      "1563/1563 [==============================] - 29s 19ms/step - loss: 0.0715 - accuracy: 0.9796 - val_loss: 3.8393 - val_accuracy: 0.6840\n",
      "Epoch 82/300\n",
      "1563/1563 [==============================] - 29s 18ms/step - loss: 0.0711 - accuracy: 0.9794 - val_loss: 3.8374 - val_accuracy: 0.6793\n",
      "Epoch 83/300\n",
      "1563/1563 [==============================] - 29s 18ms/step - loss: 0.0819 - accuracy: 0.9771 - val_loss: 4.0080 - val_accuracy: 0.6918\n",
      "Epoch 84/300\n",
      "1563/1563 [==============================] - 29s 19ms/step - loss: 0.0743 - accuracy: 0.9785 - val_loss: 4.2077 - val_accuracy: 0.6880\n",
      "Epoch 85/300\n",
      "1563/1563 [==============================] - 28s 18ms/step - loss: 0.0675 - accuracy: 0.9814 - val_loss: 3.9828 - val_accuracy: 0.6847\n",
      "Epoch 86/300\n",
      "1563/1563 [==============================] - 28s 18ms/step - loss: 0.0760 - accuracy: 0.9790 - val_loss: 4.0392 - val_accuracy: 0.6897\n",
      "Epoch 87/300\n",
      "1563/1563 [==============================] - 29s 18ms/step - loss: 0.0641 - accuracy: 0.9820 - val_loss: 4.0488 - val_accuracy: 0.6913\n",
      "Epoch 88/300\n",
      "1563/1563 [==============================] - 29s 18ms/step - loss: 0.0733 - accuracy: 0.9801 - val_loss: 4.0265 - val_accuracy: 0.6841\n",
      "Epoch 89/300\n",
      "1563/1563 [==============================] - 29s 18ms/step - loss: 0.0652 - accuracy: 0.9812 - val_loss: 4.0822 - val_accuracy: 0.6871\n",
      "Epoch 90/300\n",
      "1563/1563 [==============================] - 29s 18ms/step - loss: 0.0773 - accuracy: 0.9790 - val_loss: 4.1267 - val_accuracy: 0.6878\n",
      "Epoch 91/300\n",
      "1563/1563 [==============================] - 29s 18ms/step - loss: 0.0703 - accuracy: 0.9814 - val_loss: 4.1033 - val_accuracy: 0.6865\n",
      "Epoch 92/300\n",
      "1563/1563 [==============================] - 29s 18ms/step - loss: 0.0706 - accuracy: 0.9806 - val_loss: 4.1357 - val_accuracy: 0.6826\n",
      "Epoch 93/300\n",
      "1563/1563 [==============================] - 29s 19ms/step - loss: 0.0672 - accuracy: 0.9809 - val_loss: 4.0577 - val_accuracy: 0.6831\n",
      "Epoch 94/300\n",
      "1563/1563 [==============================] - 29s 18ms/step - loss: 0.0711 - accuracy: 0.9806 - val_loss: 4.2027 - val_accuracy: 0.6880\n",
      "Epoch 95/300\n",
      "1563/1563 [==============================] - 29s 18ms/step - loss: 0.0689 - accuracy: 0.9815 - val_loss: 4.0845 - val_accuracy: 0.6886\n",
      "Epoch 96/300\n",
      "1563/1563 [==============================] - 28s 18ms/step - loss: 0.0677 - accuracy: 0.9819 - val_loss: 4.3552 - val_accuracy: 0.6873\n",
      "Epoch 97/300\n",
      "1563/1563 [==============================] - 29s 18ms/step - loss: 0.0682 - accuracy: 0.9822 - val_loss: 4.2840 - val_accuracy: 0.6908\n",
      "Epoch 98/300\n",
      "1563/1563 [==============================] - 28s 18ms/step - loss: 0.0676 - accuracy: 0.9821 - val_loss: 4.1533 - val_accuracy: 0.6842\n",
      "Epoch 99/300\n",
      "1563/1563 [==============================] - 29s 18ms/step - loss: 0.0647 - accuracy: 0.9827 - val_loss: 4.2818 - val_accuracy: 0.6865\n",
      "Epoch 100/300\n",
      "1563/1563 [==============================] - 28s 18ms/step - loss: 0.0634 - accuracy: 0.9820 - val_loss: 4.4137 - val_accuracy: 0.6934\n",
      "Epoch 101/300\n",
      "1563/1563 [==============================] - 28s 18ms/step - loss: 0.0775 - accuracy: 0.9801 - val_loss: 4.2183 - val_accuracy: 0.6963\n",
      "Epoch 102/300\n",
      "1563/1563 [==============================] - 28s 18ms/step - loss: 0.0660 - accuracy: 0.9823 - val_loss: 4.2411 - val_accuracy: 0.6893\n",
      "Epoch 103/300\n",
      "1563/1563 [==============================] - 28s 18ms/step - loss: 0.0663 - accuracy: 0.9830 - val_loss: 4.3934 - val_accuracy: 0.6840\n",
      "Epoch 104/300\n",
      "1563/1563 [==============================] - 28s 18ms/step - loss: 0.0715 - accuracy: 0.9814 - val_loss: 4.3060 - val_accuracy: 0.6929\n",
      "Epoch 105/300\n",
      "1563/1563 [==============================] - 28s 18ms/step - loss: 0.0716 - accuracy: 0.9815 - val_loss: 4.3794 - val_accuracy: 0.6904\n",
      "Epoch 106/300\n",
      "1563/1563 [==============================] - 28s 18ms/step - loss: 0.0670 - accuracy: 0.9831 - val_loss: 4.6580 - val_accuracy: 0.6862\n",
      "Epoch 107/300\n",
      "1563/1563 [==============================] - 28s 18ms/step - loss: 0.0650 - accuracy: 0.9830 - val_loss: 4.4439 - val_accuracy: 0.7010\n",
      "Epoch 108/300\n",
      "1563/1563 [==============================] - 29s 18ms/step - loss: 0.0661 - accuracy: 0.9830 - val_loss: 4.4675 - val_accuracy: 0.6847\n",
      "Epoch 109/300\n",
      "1563/1563 [==============================] - 29s 18ms/step - loss: 0.0755 - accuracy: 0.9808 - val_loss: 4.5800 - val_accuracy: 0.6870\n",
      "Epoch 110/300\n",
      "1563/1563 [==============================] - 29s 18ms/step - loss: 0.0598 - accuracy: 0.9833 - val_loss: 4.6559 - val_accuracy: 0.6849\n",
      "Epoch 111/300\n",
      "1563/1563 [==============================] - 28s 18ms/step - loss: 0.0780 - accuracy: 0.9810 - val_loss: 4.7407 - val_accuracy: 0.6867\n",
      "Epoch 112/300\n",
      "1563/1563 [==============================] - 29s 18ms/step - loss: 0.0580 - accuracy: 0.9840 - val_loss: 5.0057 - val_accuracy: 0.6792\n",
      "Epoch 113/300\n",
      "1563/1563 [==============================] - 28s 18ms/step - loss: 0.0763 - accuracy: 0.9812 - val_loss: 4.5330 - val_accuracy: 0.6871\n",
      "Epoch 114/300\n",
      "1563/1563 [==============================] - 28s 18ms/step - loss: 0.0656 - accuracy: 0.9831 - val_loss: 4.6392 - val_accuracy: 0.6882\n",
      "Epoch 115/300\n",
      "1563/1563 [==============================] - 29s 19ms/step - loss: 0.0693 - accuracy: 0.9821 - val_loss: 4.7757 - val_accuracy: 0.6859\n",
      "Epoch 116/300\n",
      "1563/1563 [==============================] - 28s 18ms/step - loss: 0.0619 - accuracy: 0.9840 - val_loss: 5.2627 - val_accuracy: 0.6785\n",
      "Epoch 117/300\n",
      "1563/1563 [==============================] - 29s 18ms/step - loss: 0.0718 - accuracy: 0.9817 - val_loss: 4.9242 - val_accuracy: 0.6897\n",
      "Epoch 118/300\n",
      "1563/1563 [==============================] - 29s 18ms/step - loss: 0.0635 - accuracy: 0.9839 - val_loss: 5.0515 - val_accuracy: 0.6901\n",
      "Epoch 119/300\n",
      "1563/1563 [==============================] - 29s 19ms/step - loss: 0.0774 - accuracy: 0.9806 - val_loss: 4.7081 - val_accuracy: 0.6858\n",
      "Epoch 120/300\n",
      "1563/1563 [==============================] - 29s 19ms/step - loss: 0.0598 - accuracy: 0.9847 - val_loss: 4.8217 - val_accuracy: 0.6873\n",
      "Epoch 121/300\n",
      "1563/1563 [==============================] - 29s 19ms/step - loss: 0.0724 - accuracy: 0.9813 - val_loss: 5.0809 - val_accuracy: 0.6868\n",
      "Epoch 122/300\n",
      "1563/1563 [==============================] - 31s 20ms/step - loss: 0.0737 - accuracy: 0.9816 - val_loss: 5.0898 - val_accuracy: 0.6797\n",
      "Epoch 123/300\n",
      "1563/1563 [==============================] - 34s 21ms/step - loss: 0.0652 - accuracy: 0.9846 - val_loss: 5.0548 - val_accuracy: 0.6807\n",
      "Epoch 124/300\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.0616 - accuracy: 0.9844 - val_loss: 5.3267 - val_accuracy: 0.6859\n",
      "Epoch 125/300\n",
      "1563/1563 [==============================] - 28s 18ms/step - loss: 0.0665 - accuracy: 0.9838 - val_loss: 5.2926 - val_accuracy: 0.6890\n",
      "Epoch 126/300\n",
      "1563/1563 [==============================] - 28s 18ms/step - loss: 0.0646 - accuracy: 0.9842 - val_loss: 5.1038 - val_accuracy: 0.6867\n",
      "Epoch 127/300\n",
      "1563/1563 [==============================] - 28s 18ms/step - loss: 0.0807 - accuracy: 0.9813 - val_loss: 5.0192 - val_accuracy: 0.6840\n",
      "Epoch 128/300\n",
      "1563/1563 [==============================] - 28s 18ms/step - loss: 0.0580 - accuracy: 0.9852 - val_loss: 5.1193 - val_accuracy: 0.6827\n",
      "Epoch 129/300\n",
      "1563/1563 [==============================] - 28s 18ms/step - loss: 0.0712 - accuracy: 0.9835 - val_loss: 5.3231 - val_accuracy: 0.6910\n",
      "Epoch 130/300\n",
      "1563/1563 [==============================] - 27s 17ms/step - loss: 0.0767 - accuracy: 0.9830 - val_loss: 5.1443 - val_accuracy: 0.6898\n",
      "Epoch 131/300\n",
      "1563/1563 [==============================] - 27s 17ms/step - loss: 0.0590 - accuracy: 0.9856 - val_loss: 5.2785 - val_accuracy: 0.6810\n",
      "Epoch 132/300\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.0765 - accuracy: 0.9818 - val_loss: 5.1923 - val_accuracy: 0.6865\n",
      "Epoch 133/300\n",
      "1563/1563 [==============================] - 31s 20ms/step - loss: 0.0721 - accuracy: 0.9834 - val_loss: 5.1833 - val_accuracy: 0.6930\n",
      "Epoch 134/300\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.0658 - accuracy: 0.9845 - val_loss: 5.2395 - val_accuracy: 0.6864\n",
      "Epoch 135/300\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.0707 - accuracy: 0.9835 - val_loss: 5.6453 - val_accuracy: 0.6822\n",
      "Epoch 136/300\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.0720 - accuracy: 0.9828 - val_loss: 5.4485 - val_accuracy: 0.6822\n",
      "Epoch 137/300\n",
      "1563/1563 [==============================] - 29s 19ms/step - loss: 0.0697 - accuracy: 0.9843 - val_loss: 5.5947 - val_accuracy: 0.6800\n",
      "Epoch 138/300\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.0715 - accuracy: 0.9840 - val_loss: 5.5920 - val_accuracy: 0.6825\n",
      "Epoch 139/300\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.0644 - accuracy: 0.9845 - val_loss: 5.6207 - val_accuracy: 0.6822\n",
      "Epoch 140/300\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.0609 - accuracy: 0.9859 - val_loss: 6.0627 - val_accuracy: 0.6853\n",
      "Epoch 141/300\n",
      "1563/1563 [==============================] - 32s 20ms/step - loss: 0.0809 - accuracy: 0.9819 - val_loss: 5.7170 - val_accuracy: 0.6869\n",
      "Epoch 142/300\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.0737 - accuracy: 0.9836 - val_loss: 5.5345 - val_accuracy: 0.6885\n",
      "Epoch 143/300\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.0555 - accuracy: 0.9866 - val_loss: 5.6738 - val_accuracy: 0.6872\n",
      "Epoch 144/300\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.0818 - accuracy: 0.9816 - val_loss: 5.7261 - val_accuracy: 0.6860\n",
      "Epoch 145/300\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.0647 - accuracy: 0.9847 - val_loss: 5.8605 - val_accuracy: 0.6821\n",
      "Epoch 146/300\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.0597 - accuracy: 0.9850 - val_loss: 5.7460 - val_accuracy: 0.6819\n",
      "Epoch 147/300\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.0722 - accuracy: 0.9836 - val_loss: 5.8616 - val_accuracy: 0.6850\n",
      "Epoch 148/300\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.0738 - accuracy: 0.9845 - val_loss: 5.8333 - val_accuracy: 0.6804\n",
      "Epoch 149/300\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.0646 - accuracy: 0.9845 - val_loss: 5.9930 - val_accuracy: 0.6836\n",
      "Epoch 150/300\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.0606 - accuracy: 0.9856 - val_loss: 5.9864 - val_accuracy: 0.6878\n",
      "Epoch 151/300\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.0762 - accuracy: 0.9830 - val_loss: 5.9486 - val_accuracy: 0.6840\n",
      "Epoch 152/300\n",
      "1563/1563 [==============================] - 29s 19ms/step - loss: 0.0695 - accuracy: 0.9843 - val_loss: 6.3343 - val_accuracy: 0.6825\n",
      "Epoch 153/300\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.0731 - accuracy: 0.9841 - val_loss: 6.1981 - val_accuracy: 0.6824\n",
      "Epoch 154/300\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.0682 - accuracy: 0.9846 - val_loss: 6.2549 - val_accuracy: 0.6833\n",
      "Epoch 155/300\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.0702 - accuracy: 0.9857 - val_loss: 6.2710 - val_accuracy: 0.6870\n",
      "Epoch 156/300\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.0670 - accuracy: 0.9860 - val_loss: 6.4176 - val_accuracy: 0.6872\n",
      "Epoch 157/300\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.0690 - accuracy: 0.9852 - val_loss: 6.1883 - val_accuracy: 0.6813\n",
      "Epoch 158/300\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.0761 - accuracy: 0.9836 - val_loss: 6.3025 - val_accuracy: 0.6853\n",
      "Epoch 159/300\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.0661 - accuracy: 0.9868 - val_loss: 6.3669 - val_accuracy: 0.6858\n",
      "Epoch 160/300\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.0700 - accuracy: 0.9842 - val_loss: 6.4972 - val_accuracy: 0.6868\n",
      "Epoch 161/300\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.0666 - accuracy: 0.9858 - val_loss: 6.3411 - val_accuracy: 0.6950\n",
      "Epoch 162/300\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.0769 - accuracy: 0.9845 - val_loss: 6.3390 - val_accuracy: 0.6875\n",
      "Epoch 163/300\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.0681 - accuracy: 0.9856 - val_loss: 6.2747 - val_accuracy: 0.6792\n",
      "Epoch 164/300\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.0598 - accuracy: 0.9874 - val_loss: 6.6110 - val_accuracy: 0.6794\n",
      "Epoch 165/300\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.0764 - accuracy: 0.9838 - val_loss: 6.1800 - val_accuracy: 0.6848\n",
      "Epoch 166/300\n",
      "1563/1563 [==============================] - 29s 18ms/step - loss: 0.0582 - accuracy: 0.9867 - val_loss: 6.4823 - val_accuracy: 0.6844\n",
      "Epoch 167/300\n",
      "1563/1563 [==============================] - 29s 19ms/step - loss: 0.0751 - accuracy: 0.9842 - val_loss: 6.3718 - val_accuracy: 0.6784\n",
      "Epoch 168/300\n",
      "1563/1563 [==============================] - 29s 19ms/step - loss: 0.0712 - accuracy: 0.9853 - val_loss: 6.5920 - val_accuracy: 0.6935\n",
      "Epoch 169/300\n",
      "1563/1563 [==============================] - 29s 19ms/step - loss: 0.0685 - accuracy: 0.9864 - val_loss: 6.6815 - val_accuracy: 0.6822\n",
      "Epoch 170/300\n",
      "1563/1563 [==============================] - 29s 19ms/step - loss: 0.0850 - accuracy: 0.9829 - val_loss: 6.6913 - val_accuracy: 0.6893\n",
      "Epoch 171/300\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.0657 - accuracy: 0.9866 - val_loss: 6.6411 - val_accuracy: 0.6745\n",
      "Epoch 172/300\n",
      "1563/1563 [==============================] - 29s 19ms/step - loss: 0.0735 - accuracy: 0.9850 - val_loss: 6.9641 - val_accuracy: 0.6822\n",
      "Epoch 173/300\n",
      "1563/1563 [==============================] - 29s 19ms/step - loss: 0.0826 - accuracy: 0.9838 - val_loss: 6.8520 - val_accuracy: 0.6827\n",
      "Epoch 174/300\n",
      "1563/1563 [==============================] - 29s 18ms/step - loss: 0.0671 - accuracy: 0.9862 - val_loss: 7.1695 - val_accuracy: 0.6744\n",
      "Epoch 175/300\n",
      "1563/1563 [==============================] - 29s 19ms/step - loss: 0.0719 - accuracy: 0.9863 - val_loss: 6.9466 - val_accuracy: 0.6874\n",
      "Epoch 176/300\n",
      "1563/1563 [==============================] - 29s 18ms/step - loss: 0.0714 - accuracy: 0.9855 - val_loss: 6.8809 - val_accuracy: 0.6868\n",
      "Epoch 177/300\n",
      "1563/1563 [==============================] - 29s 19ms/step - loss: 0.0771 - accuracy: 0.9849 - val_loss: 6.8773 - val_accuracy: 0.6852\n",
      "Epoch 178/300\n",
      "1563/1563 [==============================] - 29s 19ms/step - loss: 0.0648 - accuracy: 0.9864 - val_loss: 6.8394 - val_accuracy: 0.6880\n",
      "Epoch 179/300\n",
      "1563/1563 [==============================] - 29s 19ms/step - loss: 0.0756 - accuracy: 0.9847 - val_loss: 7.1657 - val_accuracy: 0.6834\n",
      "Epoch 180/300\n",
      "1563/1563 [==============================] - 29s 18ms/step - loss: 0.0726 - accuracy: 0.9867 - val_loss: 7.3086 - val_accuracy: 0.6835\n",
      "Epoch 181/300\n",
      "1563/1563 [==============================] - 29s 18ms/step - loss: 0.0834 - accuracy: 0.9850 - val_loss: 6.7589 - val_accuracy: 0.6833\n",
      "Epoch 182/300\n",
      "1563/1563 [==============================] - 29s 19ms/step - loss: 0.0624 - accuracy: 0.9875 - val_loss: 7.0492 - val_accuracy: 0.6896\n",
      "Epoch 183/300\n",
      "1563/1563 [==============================] - 29s 18ms/step - loss: 0.0828 - accuracy: 0.9847 - val_loss: 7.0307 - val_accuracy: 0.6839\n",
      "Epoch 184/300\n",
      "1563/1563 [==============================] - 29s 18ms/step - loss: 0.0760 - accuracy: 0.9859 - val_loss: 6.9721 - val_accuracy: 0.6904\n",
      "Epoch 185/300\n",
      "1563/1563 [==============================] - 29s 19ms/step - loss: 0.0697 - accuracy: 0.9864 - val_loss: 7.1223 - val_accuracy: 0.6842\n",
      "Epoch 186/300\n",
      "1563/1563 [==============================] - 29s 18ms/step - loss: 0.0663 - accuracy: 0.9866 - val_loss: 7.1877 - val_accuracy: 0.6896\n",
      "Epoch 187/300\n",
      "1563/1563 [==============================] - 29s 18ms/step - loss: 0.0808 - accuracy: 0.9853 - val_loss: 7.0622 - val_accuracy: 0.6797\n",
      "Epoch 188/300\n",
      "1563/1563 [==============================] - 29s 18ms/step - loss: 0.0744 - accuracy: 0.9859 - val_loss: 7.8264 - val_accuracy: 0.6800\n",
      "Epoch 189/300\n",
      "1563/1563 [==============================] - 29s 18ms/step - loss: 0.0771 - accuracy: 0.9864 - val_loss: 7.6018 - val_accuracy: 0.6790\n",
      "Epoch 190/300\n",
      "1563/1563 [==============================] - 29s 19ms/step - loss: 0.0786 - accuracy: 0.9864 - val_loss: 7.6015 - val_accuracy: 0.6825\n",
      "Epoch 191/300\n",
      "1563/1563 [==============================] - 29s 19ms/step - loss: 0.0736 - accuracy: 0.9864 - val_loss: 7.2723 - val_accuracy: 0.6839\n",
      "Epoch 192/300\n",
      "1563/1563 [==============================] - 29s 19ms/step - loss: 0.0723 - accuracy: 0.9862 - val_loss: 7.7619 - val_accuracy: 0.6795\n",
      "Epoch 193/300\n",
      "1563/1563 [==============================] - 29s 19ms/step - loss: 0.0804 - accuracy: 0.9857 - val_loss: 7.6934 - val_accuracy: 0.6866\n",
      "Epoch 194/300\n",
      "1563/1563 [==============================] - 29s 19ms/step - loss: 0.0704 - accuracy: 0.9873 - val_loss: 7.6380 - val_accuracy: 0.6792\n",
      "Epoch 195/300\n",
      "1563/1563 [==============================] - 29s 18ms/step - loss: 0.0804 - accuracy: 0.9857 - val_loss: 7.4960 - val_accuracy: 0.6822\n",
      "Epoch 196/300\n",
      "1563/1563 [==============================] - 29s 19ms/step - loss: 0.0839 - accuracy: 0.9855 - val_loss: 7.9730 - val_accuracy: 0.6806\n",
      "Epoch 197/300\n",
      "1563/1563 [==============================] - 29s 18ms/step - loss: 0.0751 - accuracy: 0.9865 - val_loss: 7.5614 - val_accuracy: 0.6850\n",
      "Epoch 198/300\n",
      "1563/1563 [==============================] - 29s 18ms/step - loss: 0.0742 - accuracy: 0.9865 - val_loss: 7.7068 - val_accuracy: 0.6862\n",
      "Epoch 199/300\n",
      "1563/1563 [==============================] - 29s 18ms/step - loss: 0.0793 - accuracy: 0.9858 - val_loss: 7.8616 - val_accuracy: 0.6859\n",
      "Epoch 200/300\n",
      "1563/1563 [==============================] - 29s 18ms/step - loss: 0.0756 - accuracy: 0.9867 - val_loss: 8.3386 - val_accuracy: 0.6818\n",
      "Epoch 201/300\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.0740 - accuracy: 0.9866 - val_loss: 7.8816 - val_accuracy: 0.6896\n",
      "Epoch 202/300\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.0752 - accuracy: 0.9871 - val_loss: 8.2699 - val_accuracy: 0.6776\n",
      "Epoch 203/300\n",
      "1563/1563 [==============================] - 29s 19ms/step - loss: 0.0857 - accuracy: 0.9859 - val_loss: 8.0588 - val_accuracy: 0.6867\n",
      "Epoch 204/300\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.0843 - accuracy: 0.9857 - val_loss: 8.2755 - val_accuracy: 0.6821\n",
      "Epoch 205/300\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.0729 - accuracy: 0.9872 - val_loss: 8.5004 - val_accuracy: 0.6842\n",
      "Epoch 206/300\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.0779 - accuracy: 0.9859 - val_loss: 8.1415 - val_accuracy: 0.6888\n",
      "Epoch 207/300\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.0746 - accuracy: 0.9870 - val_loss: 8.0572 - val_accuracy: 0.6912\n",
      "Epoch 208/300\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.0834 - accuracy: 0.9865 - val_loss: 8.1823 - val_accuracy: 0.6830\n",
      "Epoch 209/300\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.0719 - accuracy: 0.9869 - val_loss: 8.1294 - val_accuracy: 0.6883\n",
      "Epoch 210/300\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.0801 - accuracy: 0.9871 - val_loss: 8.3481 - val_accuracy: 0.6829\n",
      "Epoch 211/300\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.0782 - accuracy: 0.9867 - val_loss: 8.2676 - val_accuracy: 0.6869\n",
      "Epoch 212/300\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.0863 - accuracy: 0.9857 - val_loss: 8.5098 - val_accuracy: 0.6796\n",
      "Epoch 213/300\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.0689 - accuracy: 0.9884 - val_loss: 8.7099 - val_accuracy: 0.6846\n",
      "Epoch 214/300\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.0840 - accuracy: 0.9863 - val_loss: 8.4213 - val_accuracy: 0.6879\n",
      "Epoch 215/300\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.0778 - accuracy: 0.9876 - val_loss: 8.7405 - val_accuracy: 0.6818\n",
      "Epoch 216/300\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.0720 - accuracy: 0.9875 - val_loss: 8.7033 - val_accuracy: 0.6819\n",
      "Epoch 217/300\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.0833 - accuracy: 0.9864 - val_loss: 9.1435 - val_accuracy: 0.6785\n",
      "Epoch 218/300\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.0858 - accuracy: 0.9865 - val_loss: 8.9747 - val_accuracy: 0.6862\n",
      "Epoch 219/300\n",
      "1563/1563 [==============================] - 29s 19ms/step - loss: 0.0832 - accuracy: 0.9874 - val_loss: 8.9193 - val_accuracy: 0.6847\n",
      "Epoch 220/300\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.0839 - accuracy: 0.9870 - val_loss: 8.8496 - val_accuracy: 0.6910\n",
      "Epoch 221/300\n",
      "1563/1563 [==============================] - 28s 18ms/step - loss: 0.0714 - accuracy: 0.9877 - val_loss: 8.9022 - val_accuracy: 0.6770\n",
      "Epoch 222/300\n",
      "1563/1563 [==============================] - 28s 18ms/step - loss: 0.0748 - accuracy: 0.9875 - val_loss: 9.0404 - val_accuracy: 0.6805\n",
      "Epoch 223/300\n",
      "1563/1563 [==============================] - 29s 18ms/step - loss: 0.0913 - accuracy: 0.9863 - val_loss: 9.1244 - val_accuracy: 0.6827\n",
      "Epoch 224/300\n",
      "1563/1563 [==============================] - 29s 19ms/step - loss: 0.0761 - accuracy: 0.9877 - val_loss: 9.1529 - val_accuracy: 0.6814\n",
      "Epoch 225/300\n",
      "1563/1563 [==============================] - 32s 20ms/step - loss: 0.0822 - accuracy: 0.9870 - val_loss: 9.3270 - val_accuracy: 0.6899\n",
      "Epoch 226/300\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.0853 - accuracy: 0.9881 - val_loss: 9.3554 - val_accuracy: 0.6830\n",
      "Epoch 227/300\n",
      "1563/1563 [==============================] - 29s 19ms/step - loss: 0.0805 - accuracy: 0.9873 - val_loss: 9.4710 - val_accuracy: 0.6824\n",
      "Epoch 228/300\n",
      "1563/1563 [==============================] - 29s 19ms/step - loss: 0.0954 - accuracy: 0.9850 - val_loss: 9.0663 - val_accuracy: 0.6883\n",
      "Epoch 229/300\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.0714 - accuracy: 0.9885 - val_loss: 9.1434 - val_accuracy: 0.6854\n",
      "Epoch 230/300\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.0815 - accuracy: 0.9869 - val_loss: 9.0751 - val_accuracy: 0.6846\n",
      "Epoch 231/300\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.0773 - accuracy: 0.9883 - val_loss: 9.3897 - val_accuracy: 0.6805\n",
      "Epoch 232/300\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.0715 - accuracy: 0.9885 - val_loss: 9.3640 - val_accuracy: 0.6829\n",
      "Epoch 233/300\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.0942 - accuracy: 0.9866 - val_loss: 9.4788 - val_accuracy: 0.6844\n",
      "Epoch 234/300\n",
      "1563/1563 [==============================] - 29s 19ms/step - loss: 0.0937 - accuracy: 0.9867 - val_loss: 9.5108 - val_accuracy: 0.6800\n",
      "Epoch 235/300\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.0779 - accuracy: 0.9877 - val_loss: 9.3206 - val_accuracy: 0.6872\n",
      "Epoch 236/300\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.0786 - accuracy: 0.9879 - val_loss: 9.9506 - val_accuracy: 0.6837\n",
      "Epoch 237/300\n",
      "1563/1563 [==============================] - 31s 20ms/step - loss: 0.0712 - accuracy: 0.9887 - val_loss: 9.6137 - val_accuracy: 0.6907\n",
      "Epoch 238/300\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.0855 - accuracy: 0.9872 - val_loss: 9.5721 - val_accuracy: 0.6868\n",
      "Epoch 239/300\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.0851 - accuracy: 0.9871 - val_loss: 9.9446 - val_accuracy: 0.6833\n",
      "Epoch 240/300\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.0788 - accuracy: 0.9877 - val_loss: 10.2015 - val_accuracy: 0.6827\n",
      "Epoch 241/300\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.0775 - accuracy: 0.9888 - val_loss: 9.5430 - val_accuracy: 0.6866\n",
      "Epoch 242/300\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.0915 - accuracy: 0.9865 - val_loss: 10.1950 - val_accuracy: 0.6808\n",
      "Epoch 243/300\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.0885 - accuracy: 0.9879 - val_loss: 9.9566 - val_accuracy: 0.6894\n",
      "Epoch 244/300\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.0738 - accuracy: 0.9892 - val_loss: 10.0034 - val_accuracy: 0.6860\n",
      "Epoch 245/300\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.1069 - accuracy: 0.9858 - val_loss: 10.0107 - val_accuracy: 0.6850\n",
      "Epoch 246/300\n",
      "1563/1563 [==============================] - 29s 19ms/step - loss: 0.0683 - accuracy: 0.9897 - val_loss: 9.9550 - val_accuracy: 0.6823\n",
      "Epoch 247/300\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.0951 - accuracy: 0.9868 - val_loss: 10.1111 - val_accuracy: 0.6831\n",
      "Epoch 248/300\n",
      "1563/1563 [==============================] - 29s 19ms/step - loss: 0.0817 - accuracy: 0.9884 - val_loss: 9.9825 - val_accuracy: 0.6876\n",
      "Epoch 249/300\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.0758 - accuracy: 0.9885 - val_loss: 10.7039 - val_accuracy: 0.6840\n",
      "Epoch 250/300\n",
      "1563/1563 [==============================] - 29s 19ms/step - loss: 0.0914 - accuracy: 0.9873 - val_loss: 10.6246 - val_accuracy: 0.6755\n",
      "Epoch 251/300\n",
      "1563/1563 [==============================] - 29s 19ms/step - loss: 0.0824 - accuracy: 0.9878 - val_loss: 11.0999 - val_accuracy: 0.6853\n",
      "Epoch 252/300\n",
      "1563/1563 [==============================] - 29s 19ms/step - loss: 0.0890 - accuracy: 0.9876 - val_loss: 11.0218 - val_accuracy: 0.6824\n",
      "Epoch 253/300\n",
      "1563/1563 [==============================] - 29s 19ms/step - loss: 0.0885 - accuracy: 0.9879 - val_loss: 10.9949 - val_accuracy: 0.6869\n",
      "Epoch 254/300\n",
      "1563/1563 [==============================] - 29s 19ms/step - loss: 0.0815 - accuracy: 0.9882 - val_loss: 11.0036 - val_accuracy: 0.6840\n",
      "Epoch 255/300\n",
      "1563/1563 [==============================] - 29s 19ms/step - loss: 0.0915 - accuracy: 0.9875 - val_loss: 10.9230 - val_accuracy: 0.6824\n",
      "Epoch 256/300\n",
      "1563/1563 [==============================] - 29s 19ms/step - loss: 0.0919 - accuracy: 0.9873 - val_loss: 10.8239 - val_accuracy: 0.6805\n",
      "Epoch 257/300\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.0834 - accuracy: 0.9886 - val_loss: 11.3659 - val_accuracy: 0.6848\n",
      "Epoch 258/300\n",
      "1563/1563 [==============================] - 29s 19ms/step - loss: 0.0813 - accuracy: 0.9888 - val_loss: 10.9554 - val_accuracy: 0.6919\n",
      "Epoch 259/300\n",
      "1563/1563 [==============================] - 29s 19ms/step - loss: 0.0899 - accuracy: 0.9883 - val_loss: 10.6896 - val_accuracy: 0.6788\n",
      "Epoch 260/300\n",
      "1563/1563 [==============================] - 29s 19ms/step - loss: 0.0800 - accuracy: 0.9894 - val_loss: 11.4500 - val_accuracy: 0.6822\n",
      "Epoch 261/300\n",
      "1563/1563 [==============================] - 29s 19ms/step - loss: 0.0952 - accuracy: 0.9876 - val_loss: 11.2510 - val_accuracy: 0.6838\n",
      "Epoch 262/300\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.0893 - accuracy: 0.9879 - val_loss: 11.2611 - val_accuracy: 0.6829\n",
      "Epoch 263/300\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.0808 - accuracy: 0.9893 - val_loss: 11.4425 - val_accuracy: 0.6840\n",
      "Epoch 264/300\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.0923 - accuracy: 0.9880 - val_loss: 11.5633 - val_accuracy: 0.6883\n",
      "Epoch 265/300\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.0844 - accuracy: 0.9882 - val_loss: 11.1291 - val_accuracy: 0.6837\n",
      "Epoch 266/300\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.0774 - accuracy: 0.9893 - val_loss: 11.4389 - val_accuracy: 0.6887\n",
      "Epoch 267/300\n",
      "1563/1563 [==============================] - 29s 19ms/step - loss: 0.0963 - accuracy: 0.9872 - val_loss: 11.8927 - val_accuracy: 0.6873\n",
      "Epoch 268/300\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.0962 - accuracy: 0.9872 - val_loss: 11.8815 - val_accuracy: 0.6811\n",
      "Epoch 269/300\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.0928 - accuracy: 0.9889 - val_loss: 11.5573 - val_accuracy: 0.6890\n",
      "Epoch 270/300\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.0999 - accuracy: 0.9875 - val_loss: 11.5023 - val_accuracy: 0.6833\n",
      "Epoch 271/300\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.0914 - accuracy: 0.9885 - val_loss: 11.9028 - val_accuracy: 0.6799\n",
      "Epoch 272/300\n",
      "1563/1563 [==============================] - 29s 19ms/step - loss: 0.0789 - accuracy: 0.9894 - val_loss: 11.6487 - val_accuracy: 0.6923\n",
      "Epoch 273/300\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.0971 - accuracy: 0.9887 - val_loss: 11.8176 - val_accuracy: 0.6818\n",
      "Epoch 274/300\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.0869 - accuracy: 0.9894 - val_loss: 12.4319 - val_accuracy: 0.6827\n",
      "Epoch 275/300\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.0885 - accuracy: 0.9888 - val_loss: 12.0291 - val_accuracy: 0.6912\n",
      "Epoch 276/300\n",
      "1563/1563 [==============================] - 29s 19ms/step - loss: 0.0856 - accuracy: 0.9885 - val_loss: 12.2838 - val_accuracy: 0.6890\n",
      "Epoch 277/300\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.1088 - accuracy: 0.9875 - val_loss: 11.9763 - val_accuracy: 0.6875\n",
      "Epoch 278/300\n",
      "1563/1563 [==============================] - 29s 19ms/step - loss: 0.0844 - accuracy: 0.9892 - val_loss: 12.3888 - val_accuracy: 0.6825\n",
      "Epoch 279/300\n",
      "1563/1563 [==============================] - 29s 18ms/step - loss: 0.0894 - accuracy: 0.9888 - val_loss: 12.9859 - val_accuracy: 0.6792\n",
      "Epoch 280/300\n",
      "1563/1563 [==============================] - 29s 19ms/step - loss: 0.0895 - accuracy: 0.9892 - val_loss: 12.3471 - val_accuracy: 0.6775\n",
      "Epoch 281/300\n",
      "1563/1563 [==============================] - 29s 19ms/step - loss: 0.0915 - accuracy: 0.9884 - val_loss: 12.6948 - val_accuracy: 0.6827\n",
      "Epoch 282/300\n",
      "1563/1563 [==============================] - 29s 18ms/step - loss: 0.1043 - accuracy: 0.9880 - val_loss: 12.7987 - val_accuracy: 0.6818\n",
      "Epoch 283/300\n",
      "1563/1563 [==============================] - 29s 18ms/step - loss: 0.0925 - accuracy: 0.9890 - val_loss: 12.9944 - val_accuracy: 0.6856\n",
      "Epoch 284/300\n",
      "1563/1563 [==============================] - 29s 19ms/step - loss: 0.0982 - accuracy: 0.9883 - val_loss: 12.9419 - val_accuracy: 0.6870\n",
      "Epoch 285/300\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.0973 - accuracy: 0.9894 - val_loss: 12.6572 - val_accuracy: 0.6862\n",
      "Epoch 286/300\n",
      "1563/1563 [==============================] - 29s 19ms/step - loss: 0.1007 - accuracy: 0.9883 - val_loss: 13.3782 - val_accuracy: 0.6826\n",
      "Epoch 287/300\n",
      "1563/1563 [==============================] - 29s 19ms/step - loss: 0.0944 - accuracy: 0.9897 - val_loss: 12.8282 - val_accuracy: 0.6815\n",
      "Epoch 288/300\n",
      "1563/1563 [==============================] - 29s 19ms/step - loss: 0.0889 - accuracy: 0.9895 - val_loss: 12.8661 - val_accuracy: 0.6808\n",
      "Epoch 289/300\n",
      "1563/1563 [==============================] - 29s 19ms/step - loss: 0.1075 - accuracy: 0.9882 - val_loss: 12.8231 - val_accuracy: 0.6816\n",
      "Epoch 290/300\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.0868 - accuracy: 0.9895 - val_loss: 13.0317 - val_accuracy: 0.6852\n",
      "Epoch 291/300\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.0887 - accuracy: 0.9895 - val_loss: 13.2701 - val_accuracy: 0.6864\n",
      "Epoch 292/300\n",
      "1563/1563 [==============================] - 29s 18ms/step - loss: 0.0926 - accuracy: 0.9890 - val_loss: 13.4618 - val_accuracy: 0.6830\n",
      "Epoch 293/300\n",
      "1563/1563 [==============================] - 29s 19ms/step - loss: 0.0906 - accuracy: 0.9891 - val_loss: 14.0095 - val_accuracy: 0.6834\n",
      "Epoch 294/300\n",
      "1563/1563 [==============================] - 29s 19ms/step - loss: 0.1027 - accuracy: 0.9882 - val_loss: 14.1091 - val_accuracy: 0.6779\n",
      "Epoch 295/300\n",
      "1563/1563 [==============================] - 29s 19ms/step - loss: 0.0943 - accuracy: 0.9901 - val_loss: 13.2322 - val_accuracy: 0.6836\n",
      "Epoch 296/300\n",
      "1563/1563 [==============================] - 29s 19ms/step - loss: 0.0937 - accuracy: 0.9893 - val_loss: 14.2349 - val_accuracy: 0.6807\n",
      "Epoch 297/300\n",
      "1563/1563 [==============================] - 29s 19ms/step - loss: 0.1020 - accuracy: 0.9888 - val_loss: 14.0554 - val_accuracy: 0.6825\n",
      "Epoch 298/300\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.0911 - accuracy: 0.9896 - val_loss: 13.2659 - val_accuracy: 0.6866\n",
      "Epoch 299/300\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.0893 - accuracy: 0.9897 - val_loss: 14.1772 - val_accuracy: 0.6745\n",
      "Epoch 300/300\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.1118 - accuracy: 0.9881 - val_loss: 14.6601 - val_accuracy: 0.6730\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 14.6601 - accuracy: 0.6730\n",
      "Training Time: 300 epochs\n",
      "Training Loss: 0.11176750808954239\n",
      "Evaluation Accuracy after 300 epochs: 0.6729999780654907\n"
     ]
    }
   ],
   "source": [
    "#problem 1.a\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\n",
    "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
    "train_labels = to_categorical(train_labels, 10)\n",
    "test_labels = to_categorical(test_labels, 10)\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softmax'))  # Adjust the output size to 10 classes\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_images, train_labels, epochs=300, validation_data=(test_images, test_labels))\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "\n",
    "print(f'Training Time: 300 epochs')\n",
    "print(f'Training Loss: {history.history[\"loss\"][-1]}')\n",
    "print(f'Evaluation Accuracy after 300 epochs: {test_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5650c4bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "1563/1563 [==============================] - 56s 36ms/step - loss: 1.4634 - accuracy: 0.4617 - val_loss: 1.1418 - val_accuracy: 0.5803\n",
      "Epoch 2/25\n",
      "1563/1563 [==============================] - 56s 36ms/step - loss: 1.0026 - accuracy: 0.6415 - val_loss: 0.9430 - val_accuracy: 0.6681\n",
      "Epoch 3/25\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.8158 - accuracy: 0.7115 - val_loss: 0.8654 - val_accuracy: 0.7048\n",
      "Epoch 4/25\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.6877 - accuracy: 0.7581 - val_loss: 0.8162 - val_accuracy: 0.7234\n",
      "Epoch 5/25\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.5905 - accuracy: 0.7909 - val_loss: 0.8127 - val_accuracy: 0.7201\n",
      "Epoch 6/25\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.4996 - accuracy: 0.8225 - val_loss: 0.8184 - val_accuracy: 0.7320\n",
      "Epoch 7/25\n",
      "1563/1563 [==============================] - 56s 36ms/step - loss: 0.4167 - accuracy: 0.8520 - val_loss: 0.8760 - val_accuracy: 0.7250\n",
      "Epoch 8/25\n",
      "1563/1563 [==============================] - 56s 36ms/step - loss: 0.3471 - accuracy: 0.8781 - val_loss: 0.8824 - val_accuracy: 0.7385\n",
      "Epoch 9/25\n",
      "1563/1563 [==============================] - 56s 36ms/step - loss: 0.2968 - accuracy: 0.8966 - val_loss: 0.9548 - val_accuracy: 0.7397\n",
      "Epoch 10/25\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.2540 - accuracy: 0.9087 - val_loss: 1.0539 - val_accuracy: 0.7281\n",
      "Epoch 11/25\n",
      "1563/1563 [==============================] - 56s 36ms/step - loss: 0.2210 - accuracy: 0.9223 - val_loss: 1.0780 - val_accuracy: 0.7336\n",
      "Epoch 12/25\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.1970 - accuracy: 0.9307 - val_loss: 1.1291 - val_accuracy: 0.7355\n",
      "Epoch 13/25\n",
      "1563/1563 [==============================] - 56s 36ms/step - loss: 0.1754 - accuracy: 0.9384 - val_loss: 1.2538 - val_accuracy: 0.7246\n",
      "Epoch 14/25\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.1610 - accuracy: 0.9461 - val_loss: 1.2702 - val_accuracy: 0.7329\n",
      "Epoch 15/25\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.1585 - accuracy: 0.9455 - val_loss: 1.2717 - val_accuracy: 0.7313\n",
      "Epoch 16/25\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.1461 - accuracy: 0.9506 - val_loss: 1.3701 - val_accuracy: 0.7265\n",
      "Epoch 17/25\n",
      "1563/1563 [==============================] - 56s 36ms/step - loss: 0.1305 - accuracy: 0.9558 - val_loss: 1.4696 - val_accuracy: 0.7183\n",
      "Epoch 18/25\n",
      "1563/1563 [==============================] - 56s 36ms/step - loss: 0.1302 - accuracy: 0.9570 - val_loss: 1.3806 - val_accuracy: 0.7274\n",
      "Epoch 19/25\n",
      "1563/1563 [==============================] - 56s 36ms/step - loss: 0.1269 - accuracy: 0.9569 - val_loss: 1.4443 - val_accuracy: 0.7203\n",
      "Epoch 20/25\n",
      "1563/1563 [==============================] - 56s 36ms/step - loss: 0.1122 - accuracy: 0.9628 - val_loss: 1.5257 - val_accuracy: 0.7225\n",
      "Epoch 21/25\n",
      "1563/1563 [==============================] - 56s 36ms/step - loss: 0.1080 - accuracy: 0.9649 - val_loss: 1.5620 - val_accuracy: 0.7222\n",
      "Epoch 22/25\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.1160 - accuracy: 0.9621 - val_loss: 1.6519 - val_accuracy: 0.7184\n",
      "Epoch 23/25\n",
      "1563/1563 [==============================] - 56s 36ms/step - loss: 0.1049 - accuracy: 0.9648 - val_loss: 1.7752 - val_accuracy: 0.7245\n",
      "Epoch 24/25\n",
      "1563/1563 [==============================] - 56s 36ms/step - loss: 0.1062 - accuracy: 0.9642 - val_loss: 1.6223 - val_accuracy: 0.7205\n",
      "Epoch 25/25\n",
      "1563/1563 [==============================] - 56s 36ms/step - loss: 0.1026 - accuracy: 0.9666 - val_loss: 1.6896 - val_accuracy: 0.7258\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.6896 - accuracy: 0.7258\n",
      "Training Time: 25 epochs\n",
      "Training Loss: 0.10257863998413086\n",
      "Evaluation Accuracy after 300 epochs: 0.7257999777793884\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\n",
    "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
    "train_labels = to_categorical(train_labels, 10)\n",
    "test_labels = to_categorical(test_labels, 10)\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3), padding='same'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))  # Additional Convolutional Layer\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))  # Additional Convolutional Layer\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_images, train_labels, epochs=25, validation_data=(test_images, test_labels))\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "\n",
    "print(f'Training Time: 25 epochs')\n",
    "print(f'Training Loss: {history.history[\"loss\"][-1]}')\n",
    "print(f'Evaluation Accuracy after 300 epochs: {test_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7e9c034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1563/1563 [==============================] - 2832s 2s/step - loss: 1.3852 - accuracy: 0.4989 - val_loss: 1.3720 - val_accuracy: 0.5169\n",
      "Epoch 2/2\n",
      "1563/1563 [==============================] - 2550s 2s/step - loss: 0.9732 - accuracy: 0.6534 - val_loss: 1.1644 - val_accuracy: 0.5983\n",
      "313/313 [==============================] - 87s 278ms/step - loss: 1.1644 - accuracy: 0.5983\n",
      "Training Time: 2 epochs\n",
      "Training Loss: 0.9732245206832886\n",
      "Evaluation Accuracy after 2 epochs: 0.5982999801635742\n"
     ]
    }
   ],
   "source": [
    "#problem 2.a\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "def resnet_block(x, filters, kernel_size=3, stride=1):\n",
    "    y = layers.Conv2D(filters, kernel_size=kernel_size, strides=stride, padding='same')(x)\n",
    "    y = layers.BatchNormalization()(y)\n",
    "    y = layers.Activation('relu')(y)\n",
    "    y = layers.Conv2D(filters, kernel_size=kernel_size, strides=stride, padding='same')(y)\n",
    "    y = layers.BatchNormalization()(y)\n",
    "    # Skip connection\n",
    "    if x.shape[-1] != filters:\n",
    "        x = layers.Conv2D(filters, kernel_size=1, strides=stride, padding='same')(x)\n",
    "    y = layers.add([x, y])\n",
    "    y = layers.Activation('relu')(y)\n",
    "    return y\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\n",
    "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
    "train_labels = to_categorical(train_labels, 10)\n",
    "test_labels = to_categorical(test_labels, 10)\n",
    "\n",
    "# Build the ResNet-10 model\n",
    "input_layer = layers.Input(shape=(32, 32, 3))\n",
    "x = layers.Conv2D(64, kernel_size=3, strides=1, padding='same')(input_layer)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Activation('relu')(x)\n",
    "\n",
    "# Build Residual Blocks\n",
    "for _ in range(9):  # 9 additional blocks for ResNet-10\n",
    "    x = resnet_block(x, 64)\n",
    "\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "output_layer = layers.Dense(10, activation='softmax')(x)  # Adjust the output size to 10 classes\n",
    "\n",
    "model = models.Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_images, train_labels, epochs=2, validation_data=(test_images, test_labels))\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "\n",
    "print(f'Training Time: 2 epochs')\n",
    "print(f'Training Loss: {history.history[\"loss\"][-1]}')\n",
    "print(f'Evaluation Accuracy after 2 epochs: {test_acc}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78f4b869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1563/1563 [==============================] - 2445s 2s/step - loss: 1.9971 - accuracy: 0.4802 - val_loss: 2.8927 - val_accuracy: 0.3127\n",
      "Epoch 2/2\n",
      "1563/1563 [==============================] - 2797s 2s/step - loss: 1.3562 - accuracy: 0.6012 - val_loss: 3.3038 - val_accuracy: 0.2910\n",
      "313/313 [==============================] - 109s 348ms/step - loss: 3.3038 - accuracy: 0.2910\n",
      "Weight Decay Results:\n",
      "Training Time: 2 epochs\n",
      "Training Loss: 1.3561673164367676\n",
      "Evaluation Accuracy after 2 epochs: 0.29100000858306885\n"
     ]
    }
   ],
   "source": [
    "#problem 2.b\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, regularizers\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\n",
    "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
    "train_labels = to_categorical(train_labels, 10)\n",
    "test_labels = to_categorical(test_labels, 10)\n",
    "\n",
    "def resnet_block_weight_decay(x, filters, kernel_size=3, stride=1, weight_decay=0.001):\n",
    "    y = layers.Conv2D(filters, kernel_size=kernel_size, strides=stride, padding='same', kernel_regularizer=regularizers.l2(weight_decay))(x)\n",
    "    y = layers.BatchNormalization()(y)\n",
    "    y = layers.Activation('relu')(y)\n",
    "    y = layers.Conv2D(filters, kernel_size=kernel_size, strides=stride, padding='same', kernel_regularizer=regularizers.l2(weight_decay))(y)\n",
    "    y = layers.BatchNormalization()(y)\n",
    "    # Skip connection\n",
    "    if x.shape[-1] != filters:\n",
    "        x = layers.Conv2D(filters, kernel_size=1, strides=stride, padding='same', kernel_regularizer=regularizers.l2(weight_decay))(x)\n",
    "    y = layers.add([x, y])\n",
    "    y = layers.Activation('relu')(y)\n",
    "    return y\n",
    "\n",
    "# Build the ResNet-10 model with Weight Decay\n",
    "input_layer = layers.Input(shape=(32, 32, 3))\n",
    "x = layers.Conv2D(64, kernel_size=3, strides=1, padding='same', kernel_regularizer=regularizers.l2(0.001))(input_layer)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Activation('relu')(x)\n",
    "\n",
    "# Build Residual Blocks\n",
    "for _ in range(9):\n",
    "    x = resnet_block_weight_decay(x, 64, weight_decay=0.001)\n",
    "\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "output_layer = layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "model_weight_decay = models.Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "model_weight_decay.compile(optimizer='adam',\n",
    "                           loss='categorical_crossentropy',\n",
    "                           metrics=['accuracy'])\n",
    "\n",
    "history_weight_decay = model_weight_decay.fit(train_images, train_labels, epochs=2, validation_data=(test_images, test_labels))\n",
    "\n",
    "test_loss_weight_decay, test_acc_weight_decay = model_weight_decay.evaluate(test_images, test_labels)\n",
    "\n",
    "print(\"Weight Decay Results:\")\n",
    "print(f'Training Time: 2 epochs')\n",
    "print(f'Training Loss: {history_weight_decay.history[\"loss\"][-1]}')\n",
    "print(f'Evaluation Accuracy after 2 epochs: {test_acc_weight_decay}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79433bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1563/1563 [==============================] - 3189s 2s/step - loss: 1.4527 - accuracy: 0.4743 - val_loss: 1.7678 - val_accuracy: 0.4578\n",
      "Epoch 2/2\n",
      "1563/1563 [==============================] - 2633s 2s/step - loss: 1.0532 - accuracy: 0.6243 - val_loss: 1.3107 - val_accuracy: 0.5538\n",
      "313/313 [==============================] - 78s 250ms/step - loss: 1.3107 - accuracy: 0.5538\n",
      "Dropout Results:\n",
      "Training Time: 2 epochs\n",
      "Training Loss: 1.053152084350586\n",
      "Evaluation Accuracy after 2 epochs: 0.5537999868392944\n"
     ]
    }
   ],
   "source": [
    "#problem 2.b\n",
    "def resnet_block_dropout(x, filters, kernel_size=3, stride=1, dropout_rate=0.3):\n",
    "    y = layers.Conv2D(filters, kernel_size=kernel_size, strides=stride, padding='same')(x)\n",
    "    y = layers.BatchNormalization()(y)\n",
    "    y = layers.Activation('relu')(y)\n",
    "    y = layers.Conv2D(filters, kernel_size=kernel_size, strides=stride, padding='same')(y)\n",
    "    y = layers.BatchNormalization()(y)\n",
    "    y = layers.Dropout(dropout_rate)(y)  # Dropout layer added\n",
    "    # Skip connection\n",
    "    if x.shape[-1] != filters:\n",
    "        x = layers.Conv2D(filters, kernel_size=1, strides=stride, padding='same')(x)\n",
    "    y = layers.add([x, y])\n",
    "    y = layers.Activation('relu')(y)\n",
    "    return y\n",
    "\n",
    "# Build the ResNet-10 model with Dropout\n",
    "input_layer = layers.Input(shape=(32, 32, 3))\n",
    "x = layers.Conv2D(64, kernel_size=3, strides=1, padding='same')(input_layer)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Activation('relu')(x)\n",
    "\n",
    "# Build Residual Blocks\n",
    "for _ in range(9):\n",
    "    x = resnet_block_dropout(x, 64, dropout_rate=0.3)\n",
    "\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "output_layer = layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "model_dropout = models.Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "model_dropout.compile(optimizer='adam',\n",
    "                     loss='categorical_crossentropy',\n",
    "                     metrics=['accuracy'])\n",
    "\n",
    "history_dropout = model_dropout.fit(train_images, train_labels, epochs=2, validation_data=(test_images, test_labels))\n",
    "\n",
    "test_loss_dropout, test_acc_dropout = model_dropout.evaluate(test_images, test_labels)\n",
    "\n",
    "print(\"Dropout Results:\")\n",
    "print(f'Training Time: 2 epochs')\n",
    "print(f'Training Loss: {history_dropout.history[\"loss\"][-1]}')\n",
    "print(f'Evaluation Accuracy after 2 epochs: {test_acc_dropout}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9d0c57f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1563/1563 [==============================] - 2322s 1s/step - loss: 1.4082 - accuracy: 0.4912 - val_loss: 1.2762 - val_accuracy: 0.5386\n",
      "Epoch 2/2\n",
      "1563/1563 [==============================] - 2319s 1s/step - loss: 0.9988 - accuracy: 0.6452 - val_loss: 2.5128 - val_accuracy: 0.4001\n"
     ]
    }
   ],
   "source": [
    "#problem 2.b\n",
    "def resnet_block_batch_norm(x, filters, kernel_size=3, stride=1):\n",
    "    y = layers.Conv2D(filters, kernel_size=kernel_size, strides=stride, padding='same')(x)\n",
    "    y = layers.BatchNormalization()(y)\n",
    "    y = layers.Activation('relu')(y)\n",
    "    y = layers.Conv2D(filters, kernel_size=kernel_size, strides=stride, padding='same')(y)\n",
    "    y = layers.BatchNormalization()(y)\n",
    "    # Skip connection\n",
    "    if x.shape[-1] != filters:\n",
    "        x = layers.Conv2D(filters, kernel_size=1, strides=stride, padding='same')(x)\n",
    "    y = layers.add([x, y])\n",
    "    y = layers.Activation('relu')(y)\n",
    "    return y\n",
    "\n",
    "# Build the ResNet-10 model with Batch Normalization\n",
    "input_layer = layers.Input(shape=(32, 32, 3))\n",
    "x = layers.Conv2D(64, kernel_size=3, strides=1, padding='same')(input_layer)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Activation('relu')(x)\n",
    "\n",
    "# Build Residual Blocks\n",
    "for _ in range(9):\n",
    "    x = resnet_block_batch_norm(x, 64)\n",
    "\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "output_layer = layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "model_batch_norm = models.Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "model_batch_norm.compile(optimizer='adam',\n",
    "                         loss='categorical_crossentropy',\n",
    "                         metrics=['accuracy'])\n",
    "\n",
    "history_batch_norm = model_batch_norm.fit(train_images, train_labels, epochs=2, validation_data=(test_images, test_labels))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd4f036",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
